<configuration>

    <!--
    <springProperty scope="context" name="log.path" source="logging.file.path" defaultValue="logs"/>
    <springProperty scope="context" name="app.name" source="spring.application.name" defaultValue="app"/>
    -->
    <!-- 控制台输出 appender -->
    <appender name="CONSOLE" class="ch.qos.logback.core.ConsoleAppender">
        <encoder>
            <pattern>%d{yyyy-MM-dd HH:mm:ss.SSS} [%thread] %-5level %logger{36} - %msg%n</pattern>
        </encoder>
    </appender>

    <!-- 滚动文件输出 appender，按时间和大小滚动 -->
    <appender name="ROLLING_FILE" class="ch.qos.logback.core.rolling.RollingFileAppender">
        <!-- 滚动文件输出 appender，按时间和大小滚动 <file>${log.path}/${app.name}.log</file>-->
        <!--<file>E:/workSpace/topSource/logs/searchgateway/search-gateway-server.log</file>-->
        <rollingPolicy class="ch.qos.logback.core.rolling.SizeAndTimeBasedRollingPolicy">
            <!-- 日志文件名格式，按日期和时间分割 -->
            <!--<fileNamePattern>${log.path}/${app.name}.%d{yyyy-MM-dd}.%i.log</fileNamePattern>-->
            <fileNamePattern>E:/workSpace/topSource/logs/goodsgateway/goods-gateway-server_%d{yyyy-MM-dd}.%i.log</fileNamePattern>
            <!-- 单个日志文件最大大小 -->
            <maxFileSize>10MB</maxFileSize>
            <!-- 保存历史日志文件的最大天数 -->
            <maxHistory>30</maxHistory>
            <!-- 所有日志文件的总大小上限 -->
            <totalSizeCap>1GB</totalSizeCap>
        </rollingPolicy>
        <encoder>
            <pattern>%d{yyyy-MM-dd HH:mm:ss.SSS} [%thread] %-5level %logger{36} - %msg%n</pattern>
        </encoder>
    </appender>

    <!-- 通过 TCP 发送到 Logstash/Filebeat -->
    <appender name="ELASTIC" class="net.logstash.logback.appender.LogstashTcpSocketAppender">
        <!-- Logstash 的 TCP 输入端口 -->
        <destination>localhost:5044</destination>
        <filter class="ch.qos.logback.classic.filter.ThresholdFilter">
            <level>ERROR</level> <!-- 仅允许ERROR及以上 -->
            <onMatch>ACCEPT</onMatch>   <!-- 如果是 ERROR/FATAL，则放行 -->
            <onMismatch>DENY</onMismatch> <!-- 其他级别直接丢弃 -->
        </filter>
        <encoder class="net.logstash.logback.encoder.LogstashEncoder">
            <customFields>{"module": "topSource-goodsGatewayService", "env": "dev"}</customFields>
        </encoder>
    </appender>

    <!-- 错误级别日志的滚动文件输出 appender -->
    <appender name="ERROR_FILE" class="ch.qos.logback.core.rolling.RollingFileAppender">
        <filter class="ch.qos.logback.classic.filter.LevelFilter">
            <level>ERROR</level>
            <onMatch>ACCEPT</onMatch>
            <onMismatch>DENY</onMismatch>
        </filter>
        <!-- <file>${log.path}/${app.name}-error.log</file>  -->
        <!--<file>E:/workSpace/topSource/logs/searchgateway/search-gateway-server_error.log</file>-->
        <rollingPolicy class="ch.qos.logback.core.rolling.SizeAndTimeBasedRollingPolicy">
            <fileNamePattern>E:/workSpace/topSource/logs/goodsgateway/goods-gateway-server_error_%d{yyyy-MM-dd}.%i.log</fileNamePattern>
            <maxFileSize>10MB</maxFileSize>
            <maxHistory>30</maxHistory>
            <totalSizeCap>1GB</totalSizeCap>
        </rollingPolicy>
        <encoder>
            <pattern>%d{yyyy-MM-dd HH:mm:ss.SSS} [%thread] %-5level %logger{36} - %msg%n</pattern>
        </encoder>
    </appender>

    <!-- 配置特定包的日志级别 -->
    <logger name="com.example.demo" level="DEBUG" additivity="false">
        <appender-ref ref="CONSOLE"/>
        <appender-ref ref="ROLLING_FILE"/>
        <appender-ref ref="ERROR_FILE"/>
    </logger>


    <!-- 根日志记录器配置 -->
    <root level="INFO">
        <appender-ref ref="CONSOLE"/>
        <appender-ref ref="ROLLING_FILE"/>
        <appender-ref ref="ERROR_FILE"/>
        <appender-ref ref="ELASTIC" />
    </root>

</configuration>